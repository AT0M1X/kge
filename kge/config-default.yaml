job:
  type: train                 # train, eval, grid, ...
  device: 'cuda'

## INPUT/OUTPUT ################################################################

dataset:
  name: 'toy'

  # training, validation, and test data files have the following fields, all
  # tab-separated:
  # - 0: subject index
  # - 1: relation index
  # - 2: object index
  # - 3-...: arbitrary metadata fields
  # Indexes are assumed to be dense throughout.
  train: train.del
  valid: valid.del
  test: test.del

  # entity and relation maps store auxiliary information about each
  # entity/predicate. Fields are tab-separated:
  # - 0: entity/predicate index (as in train/valid/test)
  # - 1...: arbitrary metadata fields
  entity_map: entity_map.del
  relation_map: relation_map.del

output:
  # Main folder where logs, checkpoints, traces, and model output are stored.
  # If left unspecified, defaults to local/experiments/<date>-<dataset>-<model>
  folder: ''
  logfile: 'kge.log'
  tracefile: 'trace.yaml'   # one yaml entry per line

## MODEL #######################################################################
## Model and its hyperparameters. Used for all jobs.

model:
  type: ''                    # distmult, complex, transe, conve

lookup_embedder:
  dim: 100                    # entity dimensionality or [ entity, relation ] dimensionality
  initialize: normal          # xavier, uniform, normal
  initialize_arg: 0.1         # gain for Xavier, range for uniform, stddev for Normal
  dropout: 0.                 # dropout used for embeddings
  # TODO l2_reg: 0.01                # use L2 regularization
  sparse: False               # ??
  normalize: ''               # alternatively: normalize '', L2

## TRAINING ####################################################################
## Used for training jobs.

train:
  type: 1toN                  # 1toN, negative_sampling
  max_epochs: 20
  optimizer: Adagrad          # sgd, adagrad, adam
  optimizer_args:
    # No default arguments are specified. Here, +++ signals that this option
    # allows arbitrary additional key-value pairs.
    +++: +++
  batch_size: 100
  loss: bce                   # bce, TODO
  num_workers: 0
  pin_memory: False
  trace_level: epoch          # batch or epoch

# configuration options for model validation/selection during training
valid:
  every: 5                    # epochs (disable with 0)
  metric: mean_reciprocal_rank_filtered  # mean_rank(_filtered), mean_reciprocal_rank_(filtered), hits@k(_filtered) for some integer k <= eval.max_k
  early_stopping: 0           # 0=disable, else:
  trace_level: epoch          # example or batch or epoch

  # Whether test data should be leaked into validation (seriously!). Filtered
  # metrics by default only use train and validation data. When this is set to
  # True, additionally produces "filtered_with_test" validation metrics (such as
  # MRR or HITS@k). Apparrently, many existing models have been trained with
  # this set to True during model selection and using a metric such as
  # mean_reciprocal_rank_filtered_with_test.
  filter_with_test: False

checkpoint:
  every: 5                    # epochs (disable with 0)
  basefile: 'checkpoint'      # add _epoch.pt

## EVALUATION ##################################################################
## Used for evaluation jobs.

# fixed metrics: compute MRR and HITS@1, ..., HITS@k
eval:
  data: valid
  type: entity_ranking
  max_k: 10                       # maximum k for HITS@k
  batch_size: 100
  num_workers: 0
  pin_memory: False
  trace_level: example            # example or batch or epoch

## GRID SEARCH #################################################################

# Metajob for a grid search
grid:
  run: True                    # if false, only creates folders and configurations

  # Define the grid. This is a list of key-array pairs, where the key is a
  # (flattened or nested) configuration option (e.g., "train.optimizer_args.lr")
  # and the value is an array of grid-search values (e.g., [ 0.1, 0.01 ]). No
  # default values specified.
  options:
    +++: +++
